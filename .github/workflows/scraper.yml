# 워크플로우 이름
name: Daily SSG Scraper

# 언제 실행할지 정의
on:
  schedule:
    # cron 스케줄 문법: 매일 아침 10시(KST)는 UTC 기준 새벽 1시입니다.
    - cron: '0 1 * * *'
  # "Actions" 탭에서 수동으로 실행할 수도 있게 함
  workflow_dispatch:

# 어떤 작업을 할지 정의
jobs:
  scrape-and-save:
    # 작업은 최신 우분투(리눅스) 환경에서 실행
    runs-on: ubuntu-latest

    # 작업 단계들
    steps:
      # 1. 저장소의 코드를 가상 서버로 가져오기
      - name: Checkout Repository
        uses: actions/checkout@v4

      # 2. 파이썬 3.12 버전 설치하기
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      # 3. 필요한 라이브러리 설치하기
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          # openpyxl 라이브러리는 더 이상 필요 없으므로 삭제
          pip install pandas selenium supabase

      # 4. 파이썬 스크립트 실행하기
      - name: Run Python Scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python ssg-icn.py

      # 5. 엑셀 파일 업로드 단계를 완전히 삭제했습니다.
